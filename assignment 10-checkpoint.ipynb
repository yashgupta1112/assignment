{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "digit=load_digits()\n",
    "x=digit.data\n",
    "y=digit.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e7c3a86048>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[3].reshape(8,8),cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 4\n",
    "regressor=LogisticRegression()\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted  Actual\n",
       "0            7       3\n",
       "1            0       0\n",
       "2            6       6\n",
       "3            4       4\n",
       "4            7       7\n",
       "5            6       6\n",
       "6            6       6\n",
       "7            7       7\n",
       "8            1       1\n",
       "9            4       4\n",
       "10           3       3\n",
       "11           4       4\n",
       "12           7       7\n",
       "13           5       5\n",
       "14           4       4\n",
       "15           6       6\n",
       "16           8       8\n",
       "17           1       1\n",
       "18           2       2\n",
       "19           6       6\n",
       "20           2       2\n",
       "21           8       8\n",
       "22           1       1\n",
       "23           1       8\n",
       "24           8       8\n",
       "25           3       3\n",
       "26           9       9\n",
       "27           7       7\n",
       "28           6       6\n",
       "29           9       9\n",
       "..         ...     ...\n",
       "510          1       1\n",
       "511          9       9\n",
       "512          6       6\n",
       "513          5       9\n",
       "514          3       3\n",
       "515          0       0\n",
       "516          0       0\n",
       "517          4       4\n",
       "518          3       3\n",
       "519          0       0\n",
       "520          3       3\n",
       "521          7       7\n",
       "522          0       0\n",
       "523          3       3\n",
       "524          6       6\n",
       "525          1       1\n",
       "526          9       9\n",
       "527          4       4\n",
       "528          4       4\n",
       "529          9       9\n",
       "530          1       1\n",
       "531          9       9\n",
       "532          3       3\n",
       "533          2       2\n",
       "534          4       4\n",
       "535          1       1\n",
       "536          3       3\n",
       "537          9       9\n",
       "538          1       1\n",
       "539          2       2\n",
       "\n",
       "[540 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=pd.DataFrame({\"Predicted\":pred,\"Actual\":y_test})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "#a\n",
    "regressor1=LogisticRegression()\n",
    "regressor1.fit(x_train,y_train)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "kfold=model_selection.KFold\n",
    "kfold=model_selection.KFold(n_splits=10,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90555556, 0.95      , 0.89444444, 0.91666667, 0.94444444,\n",
       "       0.97222222, 0.97777778, 0.95530726, 0.8603352 , 0.93854749])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=model_selection.cross_val_score(regressor,x,y,cv=kfold,scoring='accuracy')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931530105524519"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45788103, -0.14423066, -0.61750718, -0.27275699, -0.27594926,\n",
       "       -0.12823227, -0.11029206, -0.12335128, -0.62646858, -0.68574502])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b\n",
    "result2=model_selection.cross_val_score(regressor,x,y,cv=kfold,scoring='neg_log_loss')\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.34424143158838305"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73184699, 0.86942354, 0.81023661, 0.79423609, 0.82434177,\n",
       "       0.94343263, 0.92524112, 0.90725247, 0.60169024, 0.82555495])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c\n",
    "result3=model_selection.cross_val_score(regressor1,x,y,cv=kfold,scoring='r2')\n",
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233256404108781"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result3.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42222222, -0.19444444, -0.35555556, -0.32222222, -0.23888889,\n",
       "       -0.1       , -0.11111111, -0.15642458, -0.58659218, -0.27932961])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d\n",
    "result4=model_selection.cross_val_score(regressor1,x,y,cv=kfold,scoring='neg_mean_absolute_error')\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2766790813159528"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.27777778, -1.03888889, -1.56666667, -1.71111111, -1.39444444,\n",
       "       -0.47777778, -0.6       , -0.75977654, -3.29050279, -1.40782123])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e\n",
    "result5=model_selection.cross_val_score(regressor1,x,y,cv=kfold,scoring='neg_mean_squared_error')\n",
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4524767225325883"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result5.sum()/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 46  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  1  0  1  0  0]\n",
      " [ 0  0  0  0 62  0  0  0  1  1]\n",
      " [ 0  2  1  1  0 50  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 50  0  1]\n",
      " [ 0  3  1  0  0  1  0  0 49  0]\n",
      " [ 0  0  0  1  0  1  0  0  4 53]]\n"
     ]
    }
   ],
   "source": [
    "#f\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        49\n",
      "          1       0.91      0.98      0.94        52\n",
      "          2       0.96      1.00      0.98        46\n",
      "          3       0.96      0.96      0.96        57\n",
      "          4       1.00      0.97      0.98        64\n",
      "          5       0.94      0.91      0.93        55\n",
      "          6       1.00      1.00      1.00        53\n",
      "          7       0.98      0.98      0.98        51\n",
      "          8       0.91      0.91      0.91        54\n",
      "          9       0.93      0.90      0.91        59\n",
      "\n",
      "avg / total       0.96      0.96      0.96       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#g\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
